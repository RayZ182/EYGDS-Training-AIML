{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T09:11:14.324149Z",
     "start_time": "2025-11-05T09:11:09.560410Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:12:31.955355Z",
     "start_time": "2025-11-05T09:12:30.428950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emp_df = pd.read_csv('employee_skills_dataset.csv')\n",
    "emp_df.head()"
   ],
   "id": "f0f944a6ed1191f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    ID           Name                  Role Seniority  Status  \\\n",
       "0  101  Alice Johnson  Full Stack Developer    Senior  Active   \n",
       "1  102      Bob Smith        Data Scientist     Staff  Active   \n",
       "2  103  Charlie Brown   Front-End Developer    Junior  Active   \n",
       "3  104   Diana Prince     Backend Developer    Senior  Active   \n",
       "4  105     Ethan Hunt       DevOps Engineer    Expert  Active   \n",
       "\n",
       "      Primary_Stack                                             Skills  \\\n",
       "0      Python/React  Python (5), Django (4), React (4), AWS (3), Po...   \n",
       "1     Python/Pandas  Python (4), Pandas (4), Scikit-learn (3), SQL ...   \n",
       "2  React/TypeScript  React (3), TypeScript (2), HTML/CSS (4), Redux...   \n",
       "3       Java/Spring  Java (5), Spring Boot (4), Kafka (3), Microser...   \n",
       "4    AWS/Kubernetes  Kubernetes (5), Terraform (5), AWS (5), CI/CD ...   \n",
       "\n",
       "   Years_Experience   Last_Project_Domain          Last_Project_Stack  \\\n",
       "0                 7               FinTech  Python, Django, React, AWS   \n",
       "1                 4            Healthcare      Python, Flask, MongoDB   \n",
       "2                 2            E-commerce              React, Node.js   \n",
       "3                10    Enterprise Banking        Java, Spring, Oracle   \n",
       "4                 8  Cloud Infrastructure  Kubernetes, Terraform, AWS   \n",
       "\n",
       "   Availability_Score                                                Bio  \n",
       "0                  90  Alice has led the development of a high-freque...  \n",
       "1                  85  Bob recently built predictive models for patie...  \n",
       "2                  75  Charlie contributed significantly to optimizin...  \n",
       "3                  95  As an expert in Enterprise Banking, Diana arch...  \n",
       "4                 100  Ethan specializes in building fully automated,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Primary_Stack</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>Last_Project_Domain</th>\n",
       "      <th>Last_Project_Stack</th>\n",
       "      <th>Availability_Score</th>\n",
       "      <th>Bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Active</td>\n",
       "      <td>Python/React</td>\n",
       "      <td>Python (5), Django (4), React (4), AWS (3), Po...</td>\n",
       "      <td>7</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Python, Django, React, AWS</td>\n",
       "      <td>90</td>\n",
       "      <td>Alice has led the development of a high-freque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Staff</td>\n",
       "      <td>Active</td>\n",
       "      <td>Python/Pandas</td>\n",
       "      <td>Python (4), Pandas (4), Scikit-learn (3), SQL ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Python, Flask, MongoDB</td>\n",
       "      <td>85</td>\n",
       "      <td>Bob recently built predictive models for patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>Front-End Developer</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Active</td>\n",
       "      <td>React/TypeScript</td>\n",
       "      <td>React (3), TypeScript (2), HTML/CSS (4), Redux...</td>\n",
       "      <td>2</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>React, Node.js</td>\n",
       "      <td>75</td>\n",
       "      <td>Charlie contributed significantly to optimizin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Diana Prince</td>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Active</td>\n",
       "      <td>Java/Spring</td>\n",
       "      <td>Java (5), Spring Boot (4), Kafka (3), Microser...</td>\n",
       "      <td>10</td>\n",
       "      <td>Enterprise Banking</td>\n",
       "      <td>Java, Spring, Oracle</td>\n",
       "      <td>95</td>\n",
       "      <td>As an expert in Enterprise Banking, Diana arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Ethan Hunt</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Active</td>\n",
       "      <td>AWS/Kubernetes</td>\n",
       "      <td>Kubernetes (5), Terraform (5), AWS (5), CI/CD ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Cloud Infrastructure</td>\n",
       "      <td>Kubernetes, Terraform, AWS</td>\n",
       "      <td>100</td>\n",
       "      <td>Ethan specializes in building fully automated,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:13:44.051227Z",
     "start_time": "2025-11-05T09:13:44.036861Z"
    }
   },
   "cell_type": "code",
   "source": "emp_df.info()",
   "id": "7cb4418ee6e00f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   15 non-null     int64 \n",
      " 1   Name                 15 non-null     object\n",
      " 2   Role                 15 non-null     object\n",
      " 3   Seniority            15 non-null     object\n",
      " 4   Status               15 non-null     object\n",
      " 5   Primary_Stack        15 non-null     object\n",
      " 6   Skills               15 non-null     object\n",
      " 7   Years_Experience     15 non-null     int64 \n",
      " 8   Last_Project_Domain  15 non-null     object\n",
      " 9   Last_Project_Stack   15 non-null     object\n",
      " 10  Availability_Score   15 non-null     int64 \n",
      " 11  Bio                  15 non-null     object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:13:41.347600Z",
     "start_time": "2025-11-05T09:13:41.308025Z"
    }
   },
   "cell_type": "code",
   "source": "emp_df['Skills'] = emp_df['Skills'].astype(str)",
   "id": "3989ef748e6cd227",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:20:41.574559Z",
     "start_time": "2025-11-05T11:20:41.558558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query employee data tool\n",
    "def query_employee_data(\n",
    "    required_skill: str,\n",
    "    min_seniority: Optional[str] = None,\n",
    "    min_years_experience: Optional[int] = 0,\n",
    "    required_domain: Optional[str] = None,\n",
    "    status_filter: Optional[List[str]] = None,\n",
    ") -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    Queries the employee database (DataFrame) to find candidates matching the specified criteria.\n",
    "    This function acts as the 'tool' the Agent uses.\n",
    "\n",
    "    Args:\n",
    "        required_skill: A mandatory skill the employee must possess (e.g., 'Python', 'Kubernetes').\n",
    "        min_seniority: Minimum seniority level (e.g., 'Mid', 'Senior', 'Expert').\n",
    "        min_years_experience: Minimum years of experience required.\n",
    "        required_domain: Specific industry experience required (e.g., 'FinTech', 'Healthcare').\n",
    "        status_filter: List of allowed statuses (e.g., ['Active', 'Bench']). Defaults to 'Active'.\n",
    "\n",
    "    Returns:\n",
    "        A JSON string containing the relevant columns of up to 10 matching employees.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Start with all active employees if no status filter is provided\n",
    "    if status_filter is None:\n",
    "        status_filter = ['Active']\n",
    "\n",
    "    filtered_df = emp_df[emp_df['Status'].isin(status_filter)].copy()\n",
    "\n",
    "    # 2. Mandatory Skill Filtering (Search within the 'Skills' column)\n",
    "    if required_skill:\n",
    "        filtered_df = filtered_df[filtered_df['Skills'].str.contains(required_skill, case=False, na=False)]\n",
    "\n",
    "    # 3. Minimum Years of Experience Filtering\n",
    "    filtered_df = filtered_df[filtered_df['Years_Experience'] >= min_years_experience]\n",
    "\n",
    "    # 4. Domain Filtering\n",
    "    if required_domain:\n",
    "        filtered_df = filtered_df[filtered_df['Last_Project_Domain'].str.contains(required_domain, case=False, na=False)]\n",
    "\n",
    "    # 5. Seniority Filtering (Simple approach: Seniority is ranked Expert > Senior > Mid > Junior)\n",
    "    if min_seniority:\n",
    "        seniority_rank = {'Junior': 1, 'Staff': 2, 'Senior': 3, 'Expert': 4}\n",
    "        min_rank = seniority_rank.get(min_seniority, 0)\n",
    "\n",
    "        # Filter where the employee's rank is greater than or equal to the minimum required rank\n",
    "        filtered_df = filtered_df[filtered_df['Seniority'].map(seniority_rank) >= min_rank]\n",
    "\n",
    "\n",
    "    # 6. Prepare Output (Focus on what the Agent needs to see for scoring)\n",
    "    result_cols = ['ID', 'Name', 'Role', 'Seniority', 'Skills', 'Years_Experience', 'Last_Project_Domain', 'Availability_Score', 'Bio']\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return \"No employees found matching all mandatory criteria.\"\n",
    "\n",
    "    # Return the top 10 results, converted to a JSON string for the Agent\n",
    "    return filtered_df[result_cols].head(10).to_json(orient='records')"
   ],
   "id": "9aab604e47834e9c",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:20:43.987743Z",
     "start_time": "2025-11-05T11:20:43.972409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Registering the Tool to Langchain\n",
    "from langchain.tools import tool\n",
    "\n",
    "# @tool decorator makes the function callable by the LLM Agent\n",
    "@tool\n",
    "def employee_data_tool(\n",
    "    required_skill: str,\n",
    "    min_seniority: Optional[str] = None,\n",
    "    min_years_experience: Optional[int] = 0,\n",
    "    required_domain: Optional[str] = None,\n",
    "    status_filter: Optional[List[str]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    TOOL: Queries the employee database (DataFrame) for candidates.\n",
    "    Use this tool FIRST to find a pool of employees based on mandatory filters\n",
    "    like skill, experience, seniority, and domain. The required_skill parameter is mandatory.\n",
    "    Returns a JSON string of up to 10 matching employees.\n",
    "    \"\"\"\n",
    "    # Call the actual worker function\n",
    "    return query_employee_data(required_skill, min_seniority, min_years_experience, required_domain, status_filter)\n",
    "\n",
    "# The 'employee_data_tool' variable is now the component you pass to your LangChain Agent."
   ],
   "id": "2da00f748ecfff47",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scoring Mechanism:\n",
    "Weighted Scoring"
   ],
   "id": "4675bbc0b114e0e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:58:41.371331Z",
     "start_time": "2025-11-05T09:58:41.309130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "# Helper function\n",
    "def parse_skills(skills_str: str) -> Dict[str, int]:\n",
    "    \"\"\"Converts the 'Python (5), React (4)' string into a dictionary.\"\"\"\n",
    "    skills_dict = {}\n",
    "    try:\n",
    "        for item in skills_str.split(','):\n",
    "            if '(' in item and ')' in item:\n",
    "                name, score_str = item.split('(')\n",
    "                score = int(score_str.replace(')', '').strip())\n",
    "                skills_dict[name.strip().lower()] = score\n",
    "    except Exception:\n",
    "        return {}\n",
    "    return skills_dict\n",
    "\n",
    "def calculate_fit_score(\n",
    "    candidate_json: str,\n",
    "    required_skills: List[Tuple[str, int]], # E.g., [('python', 4), ('react', 3)]\n",
    "    min_years: int,\n",
    "    target_domain: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculates the Objective Fit Score (0-100) for a single employee candidate\n",
    "    based on quantifiable, structured requirements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate = json.loads(candidate_json)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid candidate JSON format.\"}\n",
    "\n",
    "    total_score = 0\n",
    "    score_breakdown = {}\n",
    "\n",
    "    # ------------------\n",
    "    # A. Skill Match (Max 40 points)\n",
    "    # ------------------\n",
    "    skill_score = 0\n",
    "    candidate_skills = parse_skills(candidate.get('Skills', ''))\n",
    "\n",
    "    if required_skills:\n",
    "        skill_weight = 40 / len(required_skills)\n",
    "        for skill, min_prof in required_skills:\n",
    "            candidate_prof = candidate_skills.get(skill.lower(), 0)\n",
    "\n",
    "            if candidate_prof >= min_prof:\n",
    "                skill_score += (candidate_prof / 5) * skill_weight\n",
    "\n",
    "    total_score += skill_score\n",
    "    score_breakdown['Skill_Match'] = round(skill_score, 2)\n",
    "\n",
    "    # ------------------\n",
    "    # B. Years of Experience (Max 20 points)\n",
    "    # ------------------\n",
    "    years = candidate.get('Years_Experience', 0)\n",
    "    # Scales experience up to a maximum score reached at 10 years\n",
    "    exp_score = min(20, (years / 10) * 20)\n",
    "    total_score += exp_score\n",
    "    score_breakdown['Experience'] = round(exp_score, 2)\n",
    "\n",
    "    # ------------------\n",
    "    # C. Domain Experience (Max 15 points)\n",
    "    # ------------------\n",
    "    domain_score = 0\n",
    "    last_domain = candidate.get('Last_Project_Domain', '').lower()\n",
    "    if target_domain.lower() in last_domain:\n",
    "        domain_score = 15\n",
    "\n",
    "    total_score += domain_score\n",
    "    score_breakdown['Domain_Experience'] = domain_score\n",
    "\n",
    "    # ------------------\n",
    "    # D. Availability (Max 15 points)\n",
    "    # ------------------\n",
    "    availability = candidate.get('Availability_Score', 0)\n",
    "    avail_score = (availability / 100) * 15\n",
    "    total_score += avail_score\n",
    "    score_breakdown['Availability'] = round(avail_score, 2)\n",
    "\n",
    "    # ------------------\n",
    "    # E. Stack Match (Max 10 points)\n",
    "    # ------------------\n",
    "    stack_score = 0\n",
    "    required_stack_keywords = [s[0] for s in required_skills]\n",
    "\n",
    "    if any(keyword in candidate.get('Primary_Stack', '').lower() or keyword in candidate.get('Last_Project_Stack', '').lower() for keyword in required_stack_keywords):\n",
    "        stack_score = 10\n",
    "\n",
    "    total_score += stack_score\n",
    "    score_breakdown['Stack_Match'] = stack_score\n",
    "\n",
    "    # ------------------\n",
    "    # Final Result\n",
    "    # ------------------\n",
    "    return {\n",
    "        \"ID\": candidate.get('ID'),\n",
    "        \"Name\": candidate.get('Name'),\n",
    "        # This is the objective, deterministic score\n",
    "        \"Objective_Fit_Score\": round(total_score, 2),\n",
    "        \"Breakdown\": score_breakdown\n",
    "    }"
   ],
   "id": "7a8a92e517b1212",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:59:13.336075Z",
     "start_time": "2025-11-05T09:59:13.323900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Register it to Langchain\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def objective_fit_scoring_tool(\n",
    "    candidate_json: str,\n",
    "    required_skills_list: List[Tuple[str, int]],\n",
    "    min_years_experience: int,\n",
    "    target_project_domain: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    TOOL: Calculates the OBJECTIVE Fit Score (0-100) for a single candidate.\n",
    "    This score is based on quantifiable data: skill proficiency, years of experience, and availability.\n",
    "    The LLM Agent must call this for all filtered candidates before final ranking.\n",
    "    Returns a JSON string with the final Objective_Fit_Score.\n",
    "    \"\"\"\n",
    "    # Calls the worker function\n",
    "    result_dict = calculate_fit_score(candidate_json, required_skills_list, min_years_experience, target_project_domain)\n",
    "    return json.dumps(result_dict)\n",
    "\n",
    "# Note: We renamed the tool to clearly indicate it calculates the 'Objective' score."
   ],
   "id": "7498a118e118b416",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Semantic Scoring Tool using Cosine Similarity",
   "id": "790391a6192ce56e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:08:18.747275Z",
     "start_time": "2025-11-05T10:07:24.341070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import json\n",
    "\n",
    "# --- 1. Load Data (Using the same structure as before) ---\n",
    "employee_df = pd.read_csv('employee_skills_dataset.csv')\n",
    "\n",
    "# --- 2. Initialize Vector Store and Embedder ---\n",
    "\n",
    "# Use a highly effective and fast sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize ChromaDB (in-memory for this example, or on disk for persistence)\n",
    "client = chromadb.Client()\n",
    "# Create a collection to store the embeddings and metadata\n",
    "bio_collection = client.get_or_create_collection(\n",
    "    name=\"employee_bios\",\n",
    "    embedding_function=None # We will handle embedding externally\n",
    ")\n",
    "\n",
    "# --- 3. Embed and Load Data into ChromaDB ---\n",
    "\n",
    "documents = employee_df['Bio'].tolist()\n",
    "ids = [str(i) for i in employee_df['ID'].tolist()]\n",
    "# Convert all other columns to metadata for retrieval\n",
    "metadatas = employee_df.drop(columns=['Bio']).to_dict('records')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedding_model.encode(documents).tolist()\n",
    "\n",
    "# Load into ChromaDB\n",
    "bio_collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ],
   "id": "de559fe8ba50b9d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\PycharmProjects\\EY Day 1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The semantic match tool",
   "id": "4b5aacbcf18a6075"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:10:48.046253Z",
     "start_time": "2025-11-05T10:10:47.978571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_semantic_score(\n",
    "    project_description: str,\n",
    "    candidate_id: str,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the semantic match score (Cosine Similarity) between the\n",
    "    Project Manager's detailed request and a single employee's bio.\n",
    "\n",
    "    Args:\n",
    "        project_description: The detailed description of the type of person needed.\n",
    "        candidate_id: The ID of the employee to check (must be a string).\n",
    "\n",
    "    Returns:\n",
    "        A score between 0.0 and 1.0 representing the semantic match.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Embed the project description\n",
    "    query_embedding = embedding_model.encode(project_description).tolist()\n",
    "\n",
    "    # 2. Query the vector store for the specific employee\n",
    "    # We use a query with where_document filtering to get the single document's embedding\n",
    "    results = bio_collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        # Only check the specific candidate ID\n",
    "        where={\"ID\": int(candidate_id)},\n",
    "        n_results=1,\n",
    "    )\n",
    "\n",
    "    # Check if a result was found\n",
    "    if not results or not results['distances'] or not results['distances'][0]:\n",
    "        return 0.0\n",
    "\n",
    "    # ChromaDB's query returns the distance. We need the similarity score.\n",
    "    # Note: If using L2/Euclidean distance, similarity is not directly distance.\n",
    "    # However, since we queried one embedding against another, the distance\n",
    "    # metric returned by ChromaDB is often based on the similarity metric\n",
    "    # of the underlying space (often Cosine). For simplicity and focusing\n",
    "    # on the match rank, we'll rely on the distance proxy or re-calculate.\n",
    "\n",
    "    # A more reliable method is to retrieve the candidate's vector and manually\n",
    "    # calculate the cosine similarity, but we'll use Chroma's features here.\n",
    "\n",
    "    # For a direct Cosine Similarity calculation (if Chroma wasn't handling it):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    # Get the candidate's stored embedding\n",
    "    candidate_result = bio_collection.get(ids=[candidate_id])\n",
    "    if not candidate_result or not candidate_result['embeddings']:\n",
    "        return 0.0\n",
    "\n",
    "    candidate_embedding = candidate_result['embeddings'][0]\n",
    "\n",
    "    # Calculate similarity (returns a 1x1 array, take the single value)\n",
    "    similarity = cosine_similarity([query_embedding], [candidate_embedding])[0][0]\n",
    "\n",
    "    # Cosine Similarity is between -1 (opposite) and 1 (identical). We normalize\n",
    "    # it to 0-1 for scoring, assuming embeddings are generally positive.\n",
    "    # A standard normalization for positive-focused text embeddings (0 to 1):\n",
    "    return max(0.0, (similarity + 1) / 2)\n",
    "\n",
    "def semantic_match_tool_worker(\n",
    "    project_description: str,\n",
    "    candidate_id: int,\n",
    ") -> float:\n",
    "    \"\"\"Worker function for the LLM tool.\"\"\"\n",
    "    return calculate_semantic_score(project_description, str(candidate_id))"
   ],
   "id": "f631687d80e4852e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:37:02.781342Z",
     "start_time": "2025-11-05T10:37:02.768076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Registering the tool into Langchain\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def semantic_match_tool(\n",
    "    project_description: str,\n",
    "    candidate_id: int,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    TOOL: Calculates the SEMANTIC Match Score (0.0 - 1.0) for a single candidate.\n",
    "    This score measures how well the candidate's Bio text semantically aligns with the\n",
    "    project's required description using Cosine Similarity on vector embeddings.\n",
    "\n",
    "    Args:\n",
    "        project_description: The detailed, descriptive project needs from the manager.\n",
    "        candidate_id: The ID of the employee (integer) to check.\n",
    "\n",
    "    Returns:\n",
    "        A JSON string containing the 'Semantic_Score' for the candidate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the float score\n",
    "    score = semantic_match_tool_worker(project_description, candidate_id)\n",
    "\n",
    "    # Return as JSON string for the Agent\n",
    "    return json.dumps({\n",
    "        \"ID\": candidate_id,\n",
    "        \"Semantic_Score\": round(score, 4)\n",
    "    })"
   ],
   "id": "c1d08efd62ca02da",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The Agent Orchestration",
   "id": "10a747bc037d45fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:27:00.305128Z",
     "start_time": "2025-11-05T11:27:00.289511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are the **TalentMatch AI Agent**, an expert Project Member Allocator.\n",
    "YOUR SOLE PURPOSE IS TO FIND AND RECOMMEND THE TOP 5 CANDIDATES.\n",
    "You MUST use the provided tools to answer the request.\n",
    "When the user asks for a candidate based on a skill (e.g., 'Selenium', 'Python', 'React'), your first and only action MUST be to call the 'employee_data_tool'.\n",
    "DO NOT apologize or state you cannot help. Use the tools to complete the task.\n",
    "\n",
    "**Process:**\n",
    "1.  **Parse Request:** Analyze the user's input and extract structured requirements (required_skill, min_years, target_domain) and the detailed, descriptive part (for semantic search).\n",
    "2.  **Filter (Tool 1):** Use the `employee_data_tool` once to filter the large database down to a pool of 10-15 viable candidates based on mandatory criteria.\n",
    "3.  **Score (Tool 2 & 3):** Iterate through the filtered candidates, using two tools for a comprehensive score:\n",
    "    * Call `objective_fit_scoring_tool` to get the quantifiable score (0-100).\n",
    "    * Call `semantic_match_tool` to get the narrative match score (0.0-1.0).\n",
    "4.  **Rank & Synthesize:** Combine the two scores (70% Objective, 30% Semantic), rank the employees, and generate a concise, persuasive natural language summary for the top 5.\n",
    "\n",
    "**Tools available to you:**\n",
    "- `employee_data_tool`: For initial filtering.\n",
    "- `objective_fit_scoring_tool`: For deterministic, weighted skill/experience scoring (returns 0-100).\n",
    "- `semantic_match_tool`: For semantic alignment scoring (returns 0.0-1.0).\n",
    "\n",
    "Always use the tools first before generating the final response.\n",
    "\"\"\""
   ],
   "id": "c17182c744ef8419",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:20:29.661548Z",
     "start_time": "2025-11-05T10:20:29.652740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Langgraph class\n",
    "\n",
    "from typing import TypedDict, List, Tuple, Optional, Dict, Any\n",
    "\n",
    "# Define the data structure for a single candidate that moves through the pipeline\n",
    "class ScoredCandidate(TypedDict):\n",
    "    ID: int\n",
    "    Name: str\n",
    "    Bio: str\n",
    "    Objective_Score: float\n",
    "    Semantic_Score: float\n",
    "    Final_Score: float\n",
    "\n",
    "# Define the overall graph state\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent's workflow.\"\"\"\n",
    "\n",
    "    # 1. Input Data\n",
    "    user_request: str\n",
    "\n",
    "    # 2. Parsed Criteria (Agent's interpretation)\n",
    "    required_skill: Optional[str]\n",
    "    min_years: int\n",
    "    target_domain: Optional[str]\n",
    "    project_description: Optional[str] # Detailed text for semantic tool\n",
    "\n",
    "    # 3. Intermediate Data\n",
    "    filtered_candidates: str # JSON list from employee_data_tool\n",
    "\n",
    "    # 4. Final Results\n",
    "    scored_candidates: List[ScoredCandidate]\n",
    "    final_recommendations: str # The natural language summary\n",
    "\n",
    "    # Tool invocation\n",
    "    tool_calls: List[Tuple[str, str]]"
   ],
   "id": "4129a3c0ec437f3c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. The LLM analyzes the user input and calls the first tool.",
   "id": "43b4bdd255dd1a89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:20:33.248069Z",
     "start_time": "2025-11-05T10:20:33.239036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (Simplified Node definition for clarity - LangGraph requires defining an App with Nodes/Edges)\n",
    "\n",
    "def parse_and_filter(state: AgentState):\n",
    "    # 1. LLM Call to Parse\n",
    "    # Agent analyzes state['user_request'] and extracts:\n",
    "    #   required_skill, min_years, target_domain, project_description\n",
    "\n",
    "    # 2. LLM decides to call the first tool\n",
    "    tool_input = {\n",
    "        \"required_skill\": state['required_skill'],\n",
    "        \"min_years_experience\": state['min_years'],\n",
    "        # ... other filter parameters\n",
    "    }\n",
    "\n",
    "    # 3. Execute the employee_data_tool with the parsed input\n",
    "    filtered_json = employee_data_tool(**tool_input)\n",
    "\n",
    "    # Update state\n",
    "    return {\n",
    "        \"filtered_candidates\": filtered_json,\n",
    "        \"tool_calls\": [(\"employee_data_tool\", str(tool_input))]\n",
    "    }"
   ],
   "id": "db425d1c702c7526",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Iterative Scoring\n",
    "This is where the agent iterates and calls the two scoring tools for each of the 10 filtered candidates."
   ],
   "id": "84224902c6ff6d73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:21:34.049200Z",
     "start_time": "2025-11-05T10:21:33.971205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def score_candidates(state: AgentState):\n",
    "    # Retrieve filtered candidates and project criteria\n",
    "    candidates = json.loads(state['filtered_candidates'])\n",
    "    scored_list = []\n",
    "\n",
    "    for candidate_json in candidates:\n",
    "        candidate_dict = json.loads(candidate_json)\n",
    "\n",
    "        # --- Call Objective Scoring Tool ---\n",
    "        obj_input = {\n",
    "            \"candidate_json\": candidate_json,\n",
    "            # Pass required criteria to the scoring tool\n",
    "            \"required_skills_list\": [('python', 4), ('react', 3)], # Example: parsed from user_request\n",
    "            \"min_years_experience\": state['min_years'],\n",
    "            \"target_project_domain\": state['target_domain'],\n",
    "        }\n",
    "        obj_result = objective_fit_scoring_tool(**obj_input)\n",
    "        obj_score_data = json.loads(obj_result)\n",
    "\n",
    "        # --- Call Semantic Scoring Tool ---\n",
    "        sem_input = {\n",
    "            \"project_description\": state['project_description'],\n",
    "            \"candidate_id\": candidate_dict['ID'],\n",
    "        }\n",
    "        sem_result = semantic_match_tool(**sem_input)\n",
    "        sem_score_data = json.loads(sem_result)\n",
    "\n",
    "        # --- Combine Scores (70% Objective, 30% Semantic) ---\n",
    "        obj_score = obj_score_data.get('Objective_Fit_Score', 0)\n",
    "        sem_score = sem_score_data.get('Semantic_Score', 0) * 100 # Scale semantic score to 100\n",
    "\n",
    "        final_score = (obj_score * 0.70) + (sem_score * 0.30)\n",
    "\n",
    "        # Build the final candidate object\n",
    "        scored_list.append({\n",
    "            \"ID\": candidate_dict['ID'],\n",
    "            \"Name\": candidate_dict['Name'],\n",
    "            \"Bio\": candidate_dict['Bio'],\n",
    "            \"Objective_Score\": obj_score,\n",
    "            \"Semantic_Score\": sem_score / 100, # Store 0.0-1.0\n",
    "            \"Final_Score\": round(final_score, 2)\n",
    "        })\n",
    "\n",
    "    # Update state\n",
    "    return {\"scored_candidates\": scored_list}"
   ],
   "id": "f3c133d9b723446d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final Summary Generation",
   "id": "d18bc8ceef7d4010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:24:23.580618Z",
     "start_time": "2025-11-05T10:24:23.554595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_summary(state: AgentState):\n",
    "    # 1. Rank the candidates\n",
    "    final_ranking = sorted(\n",
    "        state['scored_candidates'],\n",
    "        key=lambda x: x['Final_Score'],\n",
    "        reverse=True\n",
    "    )[:5] # Take Top 5\n",
    "\n",
    "    # 2. LLM Call for Synthesis\n",
    "    # Craft a detailed prompt instructing the LLM to act as the final reporter.\n",
    "    synthesis_prompt = f\"\"\"\n",
    "    The final ranking of candidates is: {json.dumps(final_ranking)}.\n",
    "    The original project description was: \"{state['user_request']}\".\n",
    "\n",
    "    Generate a professional recommendation report:\n",
    "    1. List the Top 5 candidates by Final_Score.\n",
    "    2. For each candidate, provide a summary (2-3 sentences) based on their Bio and score breakdown.\n",
    "    3. Clearly state their Final_Score and briefly mention why they are a strong fit (e.g., \"High Objective score due to Python(5) proficiency, plus a high Semantic score from extensive FinTech experience\").\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM executes the prompt and generates the final text (using Mistral 7B)\n",
    "    final_report = \"...\" # Placeholder for the LLM's generated text\n",
    "\n",
    "    return {\"final_recommendations\": final_report}"
   ],
   "id": "54e8baa6bf3376c0",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementing the LLM",
   "id": "f70edd97572ee39f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:15:19.138375Z",
     "start_time": "2025-11-05T11:15:19.125079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file (recommended)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up your API key for OpenRouter (or Mistral/OpenAI if using a different setup)\n",
    "# Ensure OPENROUTER_API_KEY is set in your .env file\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "MODEL_NAME = \"mistralai/mistral-7b-instruct\""
   ],
   "id": "8d8cd4f7aaf39ac",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:37:11.379819Z",
     "start_time": "2025-11-05T10:37:11.370591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming the tool definitions from previous steps are accessible:\n",
    "# employee_data_tool\n",
    "# objective_fit_scoring_tool\n",
    "# semantic_match_tool\n",
    "\n",
    "# List of all tools the agent can use\n",
    "tools = [\n",
    "    employee_data_tool,\n",
    "    objective_fit_scoring_tool,\n",
    "    semantic_match_tool\n",
    "]\n",
    "\n",
    "print(f\"Agent initialized with {len(tools)} tools.\")"
   ],
   "id": "6fd88bf6263f13dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent initialized with 3 tools.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:33:00.346448Z",
     "start_time": "2025-11-05T11:32:59.653090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# --- Initialize the LLM ---\n",
    "# Using the standard OpenAI SDK wrapper for OpenRouter compatibility.\n",
    "# The 'base_url' directs calls to OpenRouter.\n",
    "# Adjust to ChatMistralAI if you prefer the Mistral specific SDK.\n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL_NAME,\n",
    "    temperature= 0.7,\n",
    "    api_key= api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    timeout= 60.0\n",
    ")\n",
    "\n",
    "# --- Define the Prompt ---\n",
    "# Use the SYSTEM_PROMPT defined in the Orchestration step (must be available in the notebook)\n",
    "# For simplicity, we use a standard tool-calling template and inject our system prompt\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt = prompt.partial(system_prompt=SYSTEM_PROMPT)\n",
    "\n",
    "# --- Create the Agent ---\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# --- Create the Executor ---\n",
    "# The AgentExecutor handles the loop: LLM decides tool -> Tool runs -> LLM sees result -> repeat\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"AgentExecutor is ready. Time to test the end-to-end workflow!\")"
   ],
   "id": "71da17531e8b2cd5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\PycharmProjects\\EY Day 1\\.venv\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentExecutor is ready. Time to test the end-to-end workflow!\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:33:09.486740Z",
     "start_time": "2025-11-05T11:33:03.814086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The User's Request (The full text the manager would provide)\n",
    "test_request = \"\"\"\n",
    "I need a staff who is expert in Selenium\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n--- Running Test for Request: '{test_request}' ---\")\n",
    "\n",
    "try:\n",
    "    # Run the Agent\n",
    "    result = agent_executor.invoke({\"input\": test_request})\n",
    "\n",
    "    # Print the final output generated by the LLM\n",
    "    print(\"\\n\\n--- FINAL AGENT RECOMMENDATION ---\")\n",
    "    print(result['output'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ERROR DURING EXECUTION ---\")\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Check your API key, tool definitions, and data setup (CSV/ChromaDB).\")"
   ],
   "id": "792101b4b112654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Test for Request: '\n",
      "I need a staff who is expert in Selenium\n",
      "' ---\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mSure, I will follow the below process to find the best fit.\n",
      "1. First, I will search the database for candidates with Selenium skills, considering seniority, experience, and domain if provided. If no candidates are found, I will suggest checking the filters or expanding the search criteria.\n",
      "2. Next, I will calculate the objective fit score for each candidate based on their Selenium proficiency, experience, and availability.\n",
      "3. Finally, I will calculate the semantic match score by comparing the candidate's bio with the project description to ensure a cultural and project fit. After evaluating all candidates, I will recommend the best matches based on the combined objective fit and semantic match scores.\n",
      "\n",
      "Please provide the minimum years of experience, seniority level, and domain for the search.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "--- FINAL AGENT RECOMMENDATION ---\n",
      "Sure, I will follow the below process to find the best fit.\n",
      "1. First, I will search the database for candidates with Selenium skills, considering seniority, experience, and domain if provided. If no candidates are found, I will suggest checking the filters or expanding the search criteria.\n",
      "2. Next, I will calculate the objective fit score for each candidate based on their Selenium proficiency, experience, and availability.\n",
      "3. Finally, I will calculate the semantic match score by comparing the candidate's bio with the project description to ensure a cultural and project fit. After evaluating all candidates, I will recommend the best matches based on the combined objective fit and semantic match scores.\n",
      "\n",
      "Please provide the minimum years of experience, seniority level, and domain for the search.\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b66e087a3a2e7d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
